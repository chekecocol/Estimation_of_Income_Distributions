{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#tf.debugging.set_log_device_placement(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of data:\n",
      "              0    1\n",
      "0  14609.870117  915\n",
      "1  22263.830078  915\n",
      "2   2393.419922  915\n",
      "3  18200.000000  915\n",
      "4   5983.560059  915\n",
      "5  12465.750000  915\n",
      "6  13213.700195  968\n",
      "7  12553.009766  968\n",
      "8     24.930000  968\n",
      "9  41884.921875  968\n",
      "\n",
      "First 10 elements of Y tensor:\n",
      "[4.86995649 7.42127657 0.797806621 ... 4.40456676 4.18433666 0.00831]\n",
      "\n",
      "First 10 elements of Weights tensor:\n",
      "[915 915 915 ... 968 968 968]\n",
      "\n",
      "Expanded number of observations in data:\n",
      "73871328\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_excel(\"Desktop/datos_enigh.xls\", header = None)\n",
    "print(\"\\nFirst 10 rows of data:\")\n",
    "print(data.head(10))\n",
    "data = data.to_numpy()\n",
    "# Transform to monthly income in thousands\n",
    "data = data / np.array([3000,1])\n",
    "\n",
    "# Cast into Tensorflow objects\n",
    "Y = tf.constant(data[:,0], dtype = tf.float32)\n",
    "Weights = tf.constant(data[:,1], dtype = tf.float32)\n",
    "expanded_n = tf.math.reduce_sum(Weights)\n",
    "\n",
    "# Print tensors\n",
    "print(\"\\nFirst 10 elements of Y tensor:\")\n",
    "tf.print(Y[0:9])\n",
    "print(\"\\nFirst 10 elements of Weights tensor:\")\n",
    "tf.print(Weights[0:9])\n",
    "print(\"\\nExpanded number of observations in data:\")\n",
    "tf.print(expanded_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=float32, numpy=198604540.0>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([  1282176. ,  -2394799.8, -21291136. ], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "# Test param_vec\n",
    "test_param = tf.constant([3, 1., 0.7], dtype = tf.float32)\n",
    "\n",
    "# Define target negative log-likelihood function without constraints\n",
    "@tf.function\n",
    "def target_GeneralizedGamma(param_vec, Y = Y, Weights = Weights, n = expanded_n):\n",
    "    # Retrieve distribution parameters\n",
    "    a, d, p = tf.split(param_vec, 3, axis = 0)\n",
    "    \n",
    "    # Normalize weights\n",
    "    #weights = weights / n\n",
    "    #tf.print(weights[0:9])\n",
    "    \n",
    "    # Compute negative log-likelihood\n",
    "    ll = -(n*tf.math.log((p/a**d)/tf.math.exp(tf.math.lgamma(d/p))) + (d-1)*tf.math.reduce_sum(Weights*tf.math.log(Y)) - tf.math.reduce_sum(Weights*(Y/a)**p))\n",
    "    \n",
    "    return tf.squeeze(ll)\n",
    "\n",
    "# Return target function and its gradient\n",
    "@tf.function\n",
    "def target_grad_GeneralizedGamma(param_vec):\n",
    "    return tfp.math.value_and_gradient(target_GeneralizedGamma, param_vec)\n",
    "\n",
    "print( target_grad_GeneralizedGamma(test_param) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output of optimizer:\n",
      "BfgsOptimizerResults(converged=1, failed=0, num_iterations=9, num_objective_evaluations=69, position=[2.88551736 1.144014 0.772850096], objective_value=197576048, objective_gradient=[-37150 -133019.375 289104], inverse_hessian_estimate=[[0.988262296 -0.0351199284 0.10210707]\n",
      " [-0.0351199284 0.899715602 0.312423259]\n",
      " [0.10210707 0.312423259 0.121726513]])\n",
      "\n",
      "Estimated parameters:\n",
      "[2.8855174 1.144014  0.7728501]\n",
      "\n",
      "Mean of fitted distribution:\n",
      "5.3449636313359\n"
     ]
    }
   ],
   "source": [
    "# Minimize negative log-likelihood via BFGS\n",
    "start_param = test_param\n",
    "\n",
    "optim_results = tfp.optimizer.bfgs_minimize(target_grad_GeneralizedGamma, start_param, tolerance = 1e-10)\n",
    "print(\"\\nOutput of optimizer:\")\n",
    "tf.print(optim_results)\n",
    "est_params = optim_results.position.numpy()\n",
    "\n",
    "a_fitted = tf.constant(est_params[0], dtype = tf.float64)\n",
    "d_fitted = tf.constant(est_params[1], dtype = tf.float64)\n",
    "p_fitted = tf.constant(est_params[2], dtype = tf.float64)\n",
    "\n",
    "print(\"\\nEstimated parameters:\")\n",
    "print(est_params)\n",
    "\n",
    "# Compute fitted mean\n",
    "mu_fitted = a_fitted * tf.math.exp(tf.math.lgamma((d_fitted+1)/p_fitted)) / tf.math.exp(tf.math.lgamma(d_fitted/p_fitted))\n",
    "print(\"\\nMean of fitted distribution:\")\n",
    "tf.print(mu_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient at iteration 0\n",
      "[1.62176e+06, -1401715.5, 1282472, -0.455411255]\n",
      "Parameter values at iteration 0\n",
      "0.6\n",
      "0.92\n",
      "1.01\n",
      "100000\n",
      "\n",
      "Gradient at iteration 10000\n",
      "[575184, -431868.594, 435816, -0.463336]\n",
      "Parameter values at iteration 10000\n",
      "0.389582664\n",
      "1.05692768\n",
      "0.852889895\n",
      "100000\n",
      "\n",
      "Gradient Descent took 22.085002422332764 seconds\n",
      "\n",
      "Mean of fitted distribution:\n",
      "0.536570907\n"
     ]
    }
   ],
   "source": [
    "# Minimize negative log-likelihood via gradient descent\n",
    "@tf.function\n",
    "def SGDfunction(a, d, p, lambda1, Y = Y, Weights = Weights, n = expanded_n):\n",
    "    target = -(n*tf.math.log((p/a**d)/tf.math.exp(tf.math.lgamma(d/p))) + (d-1)*tf.math.reduce_sum(Weights*tf.math.log(Y)) - tf.math.reduce_sum(Weights*(Y/a)**p)) \\\n",
    "        + lambda1 * ((a * tf.math.exp(tf.math.lgamma((d+1)/p)) / tf.math.exp(tf.math.lgamma(d/p))) - 1)\n",
    "    \n",
    "    return tf.squeeze(target)\n",
    "\n",
    "@tf.function\n",
    "def SGDfunction_minimize(Y = Y, Weights = Weights, n = expanded_n):\n",
    "    target = -(n*tf.math.log((p/a**d)/tf.math.exp(tf.math.lgamma(d/p))) + (d-1)*tf.math.reduce_sum(Weights*tf.math.log(Y)) - tf.math.reduce_sum(Weights*(Y/a)**p)) \\\n",
    "        + lambda1 * ((a * tf.math.exp(tf.math.lgamma((d+1)/p)) / tf.math.exp(tf.math.lgamma(d/p))) - 1)\n",
    "    \n",
    "    return tf.squeeze(target)\n",
    "\n",
    "# Generate tensors with initial values\n",
    "def SGD_initial_values():\n",
    "    a = tf.Variable(0.60) \n",
    "    d = tf.Variable(0.92)\n",
    "    p = tf.Variable(1.01) \n",
    "    lambda1 = tf.Variable(1e5*1.0) \n",
    "    return a, d, p, lambda1\n",
    "\n",
    "a, d, p, lambda1 = SGD_initial_values()\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate = 3e-9)\n",
    "tic = time.time()\n",
    "for i in range(10001):\n",
    "    if i%10000 == 0:\n",
    "        print(\"\\nGradient at iteration \" + str(i))\n",
    "        with tf.GradientTape() as tape:\n",
    "            function = SGDfunction(a, d, p, lambda1)\n",
    "        tf.print(tape.gradient(function, [a, d, p, lambda1]))\n",
    "        print(\"Parameter values at iteration \" + str(i))\n",
    "        tf.print(a)\n",
    "        tf.print(d)\n",
    "        tf.print(p)\n",
    "        tf.print(lambda1)\n",
    "    opt.minimize(SGDfunction_minimize, var_list = [a, d, p, lambda1])\n",
    "print(\"\\nGradient Descent took \"+str(time.time()-tic)+\" seconds\")\n",
    "\n",
    "# Compute fitted mean\n",
    "mu_fitted_2 = a * tf.math.exp(tf.math.lgamma((d+1)/p)) / tf.math.exp(tf.math.lgamma(d/p))\n",
    "print(\"\\nMean of fitted distribution:\")\n",
    "tf.print(mu_fitted_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output of optimizer:\n",
      "BfgsOptimizerResults(converged=1, failed=0, num_iterations=11, num_objective_evaluations=66, position=[1.75941372 0.285252124], objective_value=204857120, objective_gradient=[104 1152], inverse_hessian_estimate=[[2.23848156e-06 -4.07764787e-07]\n",
      " [-4.07764787e-07 7.66302435e-08]])\n",
      "\n",
      "Estimated parameters:\n",
      "0.00924701244\n",
      "1.75941372\n",
      "0.285252124\n",
      "\n",
      "Constraint is satisfied. Mean equals:\n",
      "10.1\n",
      "\n",
      "Mass above threshold of 200.0:\n",
      "0.000691972731\n"
     ]
    }
   ],
   "source": [
    "## MLE with constraints\n",
    "start_param_constrained = tf.constant([1.5, .5], dtype = tf.float32)\n",
    "\n",
    "constrained_mean = 10.1\n",
    "top_threshold = 200.\n",
    "\n",
    "\n",
    "# Define target negative log-likelihood function with constraints\n",
    "@tf.function\n",
    "def target_GeneralizedGamma_Constrained(param_vec_constrained, Y = Y, Weights = Weights, n = expanded_n):\n",
    "    # Retrieve distribution parameters\n",
    "    d, p = tf.split(param_vec_constrained, 2, axis = 0)\n",
    "    \n",
    "    a = constrained_mean / (tf.math.exp(tf.math.lgamma((d+1)/p)) / tf.math.exp(tf.math.lgamma(d/p)))\n",
    "    \n",
    "    # Compute negative log-likelihood\n",
    "    ll = -(n*tf.math.log((p/a**d)/tf.math.exp(tf.math.lgamma(d/p))) + (d-1)*tf.math.reduce_sum(Weights*tf.math.log(Y)) - tf.math.reduce_sum(Weights*(Y/a)**p))\n",
    "    \n",
    "    return tf.squeeze(ll)\n",
    "\n",
    "# Return target function and its gradient\n",
    "@tf.function\n",
    "def target_grad_GeneralizedGamma_Constrained(param_vec_constrained):\n",
    "    return tfp.math.value_and_gradient(target_GeneralizedGamma_Constrained, param_vec_constrained)\n",
    "\n",
    "# Minimize negative log-likelihood via BFGS\n",
    "optim_results_constrained = tfp.optimizer.bfgs_minimize(target_grad_GeneralizedGamma_Constrained, start_param_constrained, tolerance = 1e-10)\n",
    "print(\"\\nOutput of optimizer:\")\n",
    "tf.print(optim_results_constrained)\n",
    "est_params_constrained = optim_results_constrained.position.numpy()\n",
    "\n",
    "d_fitted_constrained = tf.constant(est_params_constrained[0], dtype = tf.float32)\n",
    "p_fitted_constrained = tf.constant(est_params_constrained[1], dtype = tf.float32)\n",
    "a_fitted_constrained = constrained_mean / (tf.math.exp(tf.math.lgamma((d_fitted_constrained+1)/p_fitted_constrained)) / tf.math.exp(tf.math.lgamma(d_fitted_constrained/p_fitted_constrained)))\n",
    "\n",
    "print(\"\\nEstimated parameters:\")\n",
    "tf.print(a_fitted_constrained)\n",
    "tf.print(d_fitted_constrained)\n",
    "tf.print(p_fitted_constrained)\n",
    "\n",
    "print(\"\\nConstraint is satisfied. Mean equals:\")\n",
    "mu_fitted_constrained = a_fitted_constrained * tf.math.exp(tf.math.lgamma((d_fitted_constrained+1)/p_fitted_constrained)) / tf.math.exp(tf.math.lgamma(d_fitted_constrained/p_fitted_constrained))\n",
    "tf.print(mu_fitted_constrained)\n",
    "\n",
    "# Verify second constraint\n",
    "@tf.function\n",
    "def CDF_GeneralizedGamma(x, a, p, d):\n",
    "    # Using the inverse gamma distribution this way yields the same as the CDF for the generalized gamma distribution\n",
    "    return tf.math.igammac( (d/p), ((x/a)**p) )\n",
    "\n",
    "print(\"\\nMass above threshold of \" + str(top_threshold) +\":\")\n",
    "tf.print( CDF_GeneralizedGamma(top_threshold, a_fitted_constrained, p_fitted_constrained, d_fitted_constrained) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
